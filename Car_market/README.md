# Описание проекта

Необходимо разработать модель для сервиса по продаже автомобилей, которая будет предсказывать стоимость автомобиля по его характеристикам.

Заказчику были выжны следующие пункты:
- качество предсказания;
- скорость предсказания;
- время обучения.

# Описание данных

**Признаки**
- DateCrawled — дата скачивания анкеты из базы
- VehicleType — тип автомобильного кузова
- RegistrationYear — год регистрации автомобиля
- Gearbox — тип коробки передач
- Power — мощность (л. с.)
- Model — модель автомобиля
- Kilometer — пробег (км)
- RegistrationMonth — месяц регистрации автомобиля
- FuelType — тип топлива
- Brand — марка автомобиля
- Repaired — была машина в ремонте или нет
- DateCreated — дата создания анкеты
- NumberOfPictures — количество фотографий автомобиля
- PostalCode — почтовый индекс владельца анкеты (пользователя)
- LastSeen — дата последней активности пользователя  

**Целевой признак**
- Price — цена (евро)

# Используемые бибиотеки

- Pandas
- matplotlib
- sklearn
- catboost
- lightgbm

# Что было сделано

1.Была проведена корреляция признаков 
![Корреляция](https://github.com/Rook-Black/Practicum/assets/108406912/37fe3db6-f4fe-4939-8ac8-2ee811c74e6e)

2. Первичная проверка на дубликаты и избавления от них
3. Был оценен каждый столбец и проанализирован. Вот некоторые интересные наблюдения:
    - Цена имеет геометрическое распределение, что логично.  
    ![Price](https://github.com/Rook-Black/Practicum/assets/108406912/ab4b3f21-6100-4adb-a3c5-72f9901e6bed)
    - Тогда как столбец мощности уже распределен нормально  
    ![Power](https://github.com/Rook-Black/Practicum/assets/108406912/46af0dd9-7990-43d3-bef6-fa4cfdda33f2)
    - Еще в данных было очень много нулевых значений в важных (по-моему мнению) столбцах, по этому появлась идея создать другой DF без нулевых значений.
4. Кодировка категориальных признаков.
5. Обучение моделей и получение резульатотв.

# Выводы

Произведя всю необходимую работу, выяснилось, что нулевые значения очень влияют на итоговый результат. Были обучены 4 модели, одна из которых не смогла пройти порог в 2500 RMSE. Остальные смогли опустить планку ниже 2000, но при этом рандомный лес обучался очень долго, в районе 15 минут, что не подходит под условия заказчика. Остаются два градиентных бустинга, которые показали схожие результаты, но LGBMRegressor обучается в разы быстрее, что и сделало его лучшим среди всех.  
![results](https://github.com/Rook-Black/Practicum/assets/108406912/b4708328-b495-4fd5-ae5b-6bf92de2692a)
